{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f83187ff",
   "metadata": {},
   "source": [
    "# t-test\n",
    "## theory\n",
    "    > main target: find mean differences bwtween two classes. Null hypothesis: no significant difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add10743",
   "metadata": {},
   "source": [
    "## scipy implementation\n",
    "```doc\n",
    "ss.ttest_ind(\n",
    "    a,\n",
    "    b,\n",
    "    axis=0,\n",
    "    equal_var=True,\n",
    "    nan_policy='propagate',\n",
    "    permutations=None,\n",
    "    random_state=None,\n",
    "    alternative='two-sided',\n",
    "    trim=0,\n",
    ")\n",
    "Docstring:\n",
    "Calculate the T-test for the means of *two independent* samples of scores.\n",
    "\n",
    "This is a two-sided test for the null hypothesis that 2 independent samples\n",
    "have identical average (expected) values. This test assumes that the\n",
    "populations have identical variances by default.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "a, b : array_like\n",
    "    The arrays must have the same shape, except in the dimension\n",
    "    corresponding to `axis` (the first, by default).\n",
    "axis : int or None, optional\n",
    "    Axis along which to compute test. If None, compute over the whole\n",
    "    arrays, `a`, and `b`.\n",
    "equal_var : bool, optional\n",
    "    If True (default), perform a standard independent 2 sample test\n",
    "    that assumes equal population variances [1]_.\n",
    "    If False, perform Welch's t-test, which does not assume equal\n",
    "    population variance [2]_.\n",
    "\n",
    "nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
    "    Defines how to handle when input contains nan.\n",
    "    The following options are available (default is 'propagate'):\n",
    "\n",
    "      * 'propagate': returns nan\n",
    "      * 'raise': throws an error\n",
    "      * 'omit': performs the calculations ignoring nan values\n",
    "\n",
    "    The 'omit' option is not currently available for permutation tests or\n",
    "    one-sided asympyotic tests.\n",
    "\n",
    "permutations : non-negative int, np.inf, or None (default), optional\n",
    "    If 0 or None (default), use the t-distribution to calculate p-values.\n",
    "    Otherwise, `permutations` is  the number of random permutations that\n",
    "    will be used to estimate p-values using a permutation test. If\n",
    "    `permutations` equals or exceeds the number of distinct partitions of\n",
    "    the pooled data, an exact test is performed instead (i.e. each\n",
    "    distinct partition is used exactly once). See Notes for details.\n",
    "\n",
    "\n",
    "random_state : {None, int, `numpy.random.Generator`,\n",
    "        `numpy.random.RandomState`}, optional\n",
    "\n",
    "    If `seed` is None (or `np.random`), the `numpy.random.RandomState`\n",
    "    singleton is used.\n",
    "    If `seed` is an int, a new ``RandomState`` instance is used,\n",
    "    seeded with `seed`.\n",
    "    If `seed` is already a ``Generator`` or ``RandomState`` instance then\n",
    "    that instance is used.\n",
    "\n",
    "    Pseudorandom number generator state used to generate permutations\n",
    "    (used only when `permutations` is not None).\n",
    "\n",
    "alternative : {'two-sided', 'less', 'greater'}, optional\n",
    "    Defines the alternative hypothesis.\n",
    "    The following options are available (default is 'two-sided'):\n",
    "\n",
    "      * 'two-sided'\n",
    "      * 'less': one-sided\n",
    "      * 'greater': one-sided\n",
    "\n",
    "trim : float, optional\n",
    "    If nonzero, performs a trimmed (Yuen's) t-test.\n",
    "    Defines the fraction of elements to be trimmed from each end of the\n",
    "    input samples. If 0 (default), no elements will be trimmed from either\n",
    "    side. The number of trimmed elements from each tail is the floor of the\n",
    "    trim times the number of elements. Valid range is [0, .5).\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9e50d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "\n",
    "data_iris = load_iris()\n",
    "data_iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dae26d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_f = data_iris[\"feature_names\"]\n",
    "iris_data = data_iris[\"data\"][:,:3]\n",
    "iris_target = data_iris.target\n",
    "iris_f[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "959b87f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 50), (1, 50), (2, 50)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "c = Counter(iris_target)\n",
    "c.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfe50508",
   "metadata": {},
   "outputs": [],
   "source": [
    "class0 = []\n",
    "class1 = []\n",
    "class2 = []\n",
    "for idx,(feature, target) in enumerate(zip(iris_data,iris_target)):\n",
    "    if target == 0:\n",
    "        class0.append(feature)\n",
    "    elif target == 1:\n",
    "        class1.append(feature)\n",
    "    else:\n",
    "        class2.append(feature)\n",
    "class0 = np.array(class0, dtype=np.float64)\n",
    "class1 = np.array(class1, dtype=np.float64)\n",
    "class2 = np.array(class2, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc0b0ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=array([-10.52098627,   9.45497585, -39.49271939]), pvalue=array([3.74674261e-17, 2.48422790e-15, 9.93443296e-46]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t-test for mean between class-0 and class-1\n",
    "ss.ttest_ind(class0,class1,axis=0,equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73062937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=array([ -5.62916526,  -3.20576075, -12.60377944]), pvalue=array([1.86614439e-07, 1.81948348e-03, 4.90028753e-22]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t-test for mean between class-1 and class-2\n",
    "ss.ttest_ind(class1,class2,axis=0,equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b201957d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=array([-15.38619582,   6.45034909, -49.98618626]), pvalue=array([3.96686727e-25, 4.57077142e-09, 9.26962759e-50]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t-test for mean between class-0 and class-2\n",
    "ss.ttest_ind(class0,class2,axis=0,equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667bc1fb",
   "metadata": {},
   "source": [
    "## notification\n",
    "> 1. due to limitation of dimensionality, t-test will only work on 1-d data, which means that it could only calculate p value one feature at a time.  <br>\n",
    "> 2. This means we assume that features are independent to each other. Instead of modeling all features as one single compound probability density function, we simply divided each variable under the assumption that they are independent to each other, and compound pdf are the product of each marginal pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9738f7",
   "metadata": {},
   "source": [
    "# scatter matrix and FDR\n",
    "> this definition will use variance(second order central distance) and mean(first order original distance)\n",
    "<br>\n",
    "> within-class scatter matrix\n",
    "$$\n",
    "    \\mathbf{S_{\\omega}} = \\displaystyle\\sum_{i=1}^{M}{p_i\\Sigma_i}\n",
    "$$\n",
    "where\n",
    "$p_i = \\frac{n_i}{N}$ is the proportion of data of certain class to the whole data set, and $M$ is the total number of classes <br>\n",
    "and $\\Sigma_i = E[(x-\\mu_i){(x-\\mu_i)}^T]$ is the covariance matrix of ith-class\n",
    "\n",
    "> between-class scatter matrix \n",
    "$$\n",
    "   \\mathbf{S_b} = \\displaystyle\\sum_{i=1}^{M}{p_i(\\mu_i-\\mu_0){(\\mu_i-\\mu_0)}^T}\n",
    "$$\n",
    "where\n",
    "$\\mu_0 = \\displaystyle\\sum_{i=1}^{M}{p_i\\mu_i}$ is the global mean matrix <br>\n",
    "\n",
    "> mixture scatter matrix\n",
    "$$\n",
    "    \\mathbf{S_m} = E[(x-\\mu_0){(x-\\mu_0)}^T]\n",
    "$$\n",
    "\n",
    "> we could easily proof\n",
    "$$\n",
    "    \\mathbf{S_m} =  \\mathbf{S_{\\omega}} +  \\mathbf{S_b}\n",
    "$$\n",
    "\n",
    "> as we can see, in two class classification, $| \\mathbf{S_{\\omega}}|$ is proportional to ${\\sigma_1}^2 + {\\sigma_2}^2$ amd $| \\mathbf{S_{b}}|$ is proportional to ${(\\mu_1 - \\mu_2)}^2$ <br>\n",
    "> thus we could define FDR(Fisher's Discriminant Ratio)\n",
    "$$\n",
    "    FDR = \\displaystyle\\sum_{i}^{M}\\displaystyle\\sum_{j \\neq i}^{M}\\frac{{(\\mu_1 - \\mu_2)}^2}{{\\sigma_1}^2 + {\\sigma_2}^2}\n",
    "$$\n",
    "\n",
    "which could be easier to memo\n",
    "$$\n",
    "    FDR \\sim \\frac{|\\mathbf{S_b}|}{|\\mathbf{S_{\\omega}}|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f4314c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
